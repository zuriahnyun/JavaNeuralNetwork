import java.util.*;


public class JavaNeuralNetwork {


    double layers;
    double neurons;
    double StepSize;

    public JavaNeuralNetwork(double layers,double neurons,double StepSize){
        this.layers = layers;
        this.neurons = neurons;
        this.StepSize = StepSize;
    }
 
    
    public static void main(String[] args){

    

    JavaNeuralNetwork Obj = new JavaNeuralNetwork(4,4,5);
    
    
    // Inputs to the neural network are the outputs from the neurons in the previous layer
    // This so far is one single Neuron
    // Each Neuron has one Bias

    // Adding an input and weight
    // Modeling a Layer, (3 Neurons)
    

    // 4x1
    double[] inputs = {1.1 , 1.5, 2, 1.3};
    

    // 3x4
    // double[] weights1 = {1.3,2.3,0.9,1.5};
    // double[] weights2 = {2,3,0.9,1.5};
    // double[] weights3 = {0,2,2,3};
    
    // Turning it into a matrix
    double[][] weights =  {
    {1.3,2.3,0.9,1.5},
    {2,3,0.9,1.5},
    {0,2,2,3}
    };

    // double bias1 = -.4;
    // double bias2 = -.3;
    // double bias3 = -.6;

    double[] biases = {-.4 ,-.3 , -.6};


    // Caveman Multiplication
    // double[] output ={ 
    //     inputs[0] * weights1[0] + inputs[1] * weights1[1] + inputs[2] * weights1[2] + inputs[3] * weights1[3] + bias1,
    //     inputs[0] * weights2[0] + inputs[1] * weights2[1] + inputs[2] * weights2[2] + inputs[3] * weights2[3] + bias2,
    //     inputs[0] * weights3[0] + inputs[1] * weights3[1] + inputs[2] * weights3[2] + inputs[3] * weights3[3] + bias3 };
    
    double[] output = Obj.layer_outputs(inputs,weights,biases);


    // This is ouputing the weights to 3 ouput neurons
    System.out.println(Arrays.toString(output));

    }


    // Method to get the outputs
    // Fix this!!!!
    public double[] layer_outputs(double[] inputs,double[][] weights,double[] biases){

        double[] layer_outputs = new double[inputs.length];

        for(int i = 0; i < weights.length; i++){

            for(int j = 0; j < weights[i].length; j++){
                layer_outputs[j] = inputs[j] * weights[i][j];
            }

        }

        for(int l = 0;l < weights[weights.length].length; l++){
            layer_outputs[l] = layer_outputs[l] + biases[l];
        }

        return layer_outputs;

    }


    // Imitating the zip method in Python
    // This method assumes that the lists are of the same length
    // This will return a list of lists where
    public double[][] zip(double[] list1,double[] list2){
        double[][] matrix = new double [list1.length][2];

        for(int i = 0; i< list1.length;i++){
            double value1 = list1[i];
            double value2 = list2[i];
            
            double[] vector = {value1,value2};
            matrix[i] = vector;
        }

        return matrix;
    }






    // Dot Product 
    public double DotProduct(double[] inputs, double[] weights){
        double sum = 0.0;
        
        if(inputs.length == weights.length){
            for(int i = 0;i< inputs.length;i++){
                sum  = sum + (inputs[i] * weights[i]);
            }
        }
        if(sum == 0.0){
            System.out.println("Inputs and Weights do not have the same number of Columns");
            return sum;
        }else{
            return sum;
        }
        
    }



    // Softmax function is defined as:
    // softmax(z_i) = exp(z_i)/sum(exp(z_j))

    // sum is a the sum of the exponential leading up to the element i
    public double softmax(double element, double sum){
        
        return Math.exp(element) / sum;
        
    }


}
